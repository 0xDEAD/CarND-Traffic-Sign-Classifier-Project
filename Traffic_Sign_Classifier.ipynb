{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Driving Car Engineer Nanodegree\n",
    "\n",
    "## Deep Learning\n",
    "\n",
    "## Project: Build a Traffic Sign Recognition Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 0: Load The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load pickled data\n",
    "import pickle\n",
    "\n",
    "training_file = \"data/train.p\"\n",
    "validation_file = \"data/valid.p\"\n",
    "testing_file = \"data/test.p\"\n",
    "\n",
    "# Load training-, validation-, and test-data\n",
    "with open(training_file, mode='rb') as f:\n",
    "    train = pickle.load(f)\n",
    "with open(validation_file, mode='rb') as f:\n",
    "    valid = pickle.load(f)\n",
    "with open(testing_file, mode='rb') as f:\n",
    "    test = pickle.load(f)\n",
    "\n",
    "# split data into images and labels\n",
    "X_train, y_train = train['features'], train['labels']\n",
    "X_valid, y_valid = valid['features'], valid['labels']\n",
    "X_test, y_test = test['features'], test['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 1: Dataset Summary & Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provide a Basic Summary of the Data Set Using Python, Numpy and/or Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Print some information on the data\n",
    "\n",
    "n_train = len(X_train)\n",
    "n_test = len(X_test)\n",
    "n_classes = len(set(y_train))\n",
    "image_shape = X_train[0].shape\n",
    "\n",
    "print(\"Number of training examples =\", n_train)\n",
    "print(\"Number of testing examples =\", n_test)\n",
    "print(\"Image data shape =\", image_shape)\n",
    "print(\"Number of classes =\", n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Include an exploratory visualization of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from numpy import where\n",
    "import pandas as pd\n",
    "\n",
    "# Visualizations will be shown in the notebook.\n",
    "%matplotlib inline\n",
    "\n",
    "# Load class names\n",
    "classes = pd.read_csv('signnames.csv', sep=',',header=1)\n",
    "\n",
    "def previewImage(image, label, name):\n",
    "    print(label, \" - \", name)\n",
    "    plt.figure(figsize = (1,1))\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# for each class find and render 1 example from test set\n",
    "for label, name in classes.values:\n",
    "    idx = where(y_test == label)[0][0]\n",
    "    previewImage(X_test[idx], label, name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Step 2: Design a Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process the Data Set (normalization and rotated duplication)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from numpy import subtract\n",
    "from numpy import divide\n",
    "import cv2\n",
    "\n",
    "def normalize(images):\n",
    "    images_prep = []\n",
    "    for image in images:\n",
    "        images_prep.append(divide(subtract(image, 128.0), 128.0))\n",
    "    return images_prep\n",
    "\n",
    "def rotate(image, angle):\n",
    "    M = cv2.getRotationMatrix2D((image.shape[0] / 2, image.shape[1] / 2), angle, 1)\n",
    "    return cv2.warpAffine(image, M, (image.shape[0], image.shape[1]))\n",
    "\n",
    "# increase number of samples for training by modifying them slightly\n",
    "def duplicate(images, labels):\n",
    "    images_dup = []\n",
    "    labels_dup = []\n",
    "    for image in images:\n",
    "        # original\n",
    "        images_dup.append(image)\n",
    "        # rotate +5\n",
    "        images_dup.append(rotate(image, 5))\n",
    "        # rotate -5\n",
    "        images_dup.append(rotate(image, -5))\n",
    "        # rotate +10\n",
    "        images_dup.append(rotate(image, 10))\n",
    "        # rotate -10\n",
    "        images_dup.append(rotate(image, -10))\n",
    "    for label in labels:\n",
    "        for duplicates in range(5):\n",
    "            labels_dup.append(label)\n",
    "    return images_dup, labels_dup\n",
    "\n",
    "X_train, y_train = duplicate(X_train, y_train)\n",
    "print(\"New number of training samples:\", len(X_train))\n",
    "X_train = normalize(X_train)\n",
    "X_valid = normalize(X_valid)\n",
    "X_test = normalize(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# implementation of the actual network\n",
    "from tensorflow.contrib.layers import flatten\n",
    "\n",
    "def SignNet(sign, shape, num_labels):\n",
    "    # constants used for tf.truncated_normal\n",
    "    mu = 0\n",
    "    sigma = 0.1    \n",
    "    \n",
    "    # Layer 1: Convolutional.\n",
    "    # Input = 32x32x3 (width x height  x 3)\n",
    "    # Output = 28x28x6 (width-4) x (height-4) x 6\n",
    "    # filter with size=5x5, stride=1\n",
    "    l1_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 3, 6), mean=mu, stddev=sigma))\n",
    "    l1_b = tf.Variable(tf.zeros(6))\n",
    "    l1_strides = [1, 1, 1, 1]\n",
    "    l1 = tf.nn.conv2d(sign, l1_W, strides=l1_strides, padding='VALID') + l1_b\n",
    "    l1 = tf.nn.relu(l1)\n",
    "\n",
    "    # maximum pooling to reduce size to 14x14x6 / (width-4)/2 x (height-4)/2 x 6\n",
    "    l1p_kernel = [1, 2, 2, 1]\n",
    "    l1p_strides = [1, 2, 2, 1]\n",
    "    l1p = tf.nn.max_pool(l1, ksize=l1p_kernel, strides=l1p_strides, padding='VALID')    \n",
    "    \n",
    "    # Layer 2: Convolutional.\n",
    "    # Input = (width-4)/2 x (height-4)/2 x 6\n",
    "    # Output = ((width-4)/2-4) x ((height-4)/2-4) x 16\n",
    "    l2_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 6, 16), mean=mu, stddev=sigma))\n",
    "    l2_b = tf.Variable(tf.zeros(16))\n",
    "    l2_strides = [1, 1, 1, 1]\n",
    "    l2 = tf.nn.conv2d(l1p, l2_W, strides=l2_strides, padding='VALID') + l2_b\n",
    "    l2 = tf.nn.relu(l2)\n",
    "    \n",
    "    # maximum pooling to reduce size to 5x5x16 / ((width-4)/2-4)/2 x ((height-4)/2-4)/2 x 16\n",
    "    l2p_kernel = [1, 2, 2, 1]\n",
    "    l2p_strides = [1, 2, 2, 1]\n",
    "    l2p = tf.nn.max_pool(l2, ksize=l2p_kernel, strides=l2p_strides, padding='VALID')\n",
    "    \n",
    "    # Flatten.\n",
    "    # Input = 5x5x16 / ((width-4)/2-4)/2 x ((height-4)/2-4)/2 x 16\n",
    "    # Output = 400 / ((width-4)/2-4)/2 * ((height-4)/2-4)/2 * 16\n",
    "    flat = flatten(l2p)\n",
    "    flat_len = 400 # FIXME\n",
    "\n",
    "    # Layer 3: Fully Connected, cut to 2/3\n",
    "    # Input = 400 / ((width-4)/2-4)/2 * ((height-4)/2-4)/2 * 16\n",
    "    # Output = 200 / ((width-4)/2-4)/2 * ((height-4)/2-4)/2 * 16 / 2\n",
    "    l3_len = 267 # FIXME\n",
    "    l3_W = tf.Variable(tf.truncated_normal(shape=(flat_len, l3_len), mean=mu, stddev=sigma))\n",
    "    l3_b = tf.Variable(tf.zeros(l3_len))\n",
    "    l3 = tf.add(tf.matmul(flat, l3_W), l3_b)\n",
    "    l3 = tf.nn.relu(l3)\n",
    "\n",
    "    # Layer 4: Fully Connected, vut to 2/3\n",
    "    # Input = 200 / ((width-4)/2-4)/2 * ((height-4)/2-4)/2 * 16 / 2\n",
    "    # Input = 100 / ((width-4)/2-4)/2 * ((height-4)/2-4)/2 * 16 / 2 / 2\n",
    "    l4_len = 178 # FIXME\n",
    "    l4_W = tf.Variable(tf.truncated_normal(shape=(l3_len, l4_len), mean=mu, stddev=sigma))\n",
    "    l4_b = tf.Variable(tf.zeros(l4_len))\n",
    "    l4 = tf.add(tf.matmul(l3, l4_W), l4_b)\n",
    "    l4 = tf.nn.relu(l4)\n",
    "\n",
    "    # Layer 5: Fully Connected. Input = 84. Output = 10.\n",
    "    l5_W = tf.Variable(tf.truncated_normal(shape=(l4_len, num_labels), mean=mu, stddev=sigma))\n",
    "    l5_b = tf.Variable(tf.zeros(num_labels))\n",
    "    logits = tf.add(tf.matmul(l4, l5_W), l5_b)\n",
    "\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# placeholders for batches(x=input images, y=output labels)\n",
    "\n",
    "sign = tf.placeholder(tf.float32, (None, image_shape[0], image_shape[1], image_shape[2]))\n",
    "y = tf.placeholder(tf.int32, (None))\n",
    "one_hot_y = tf.one_hot(y, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# training pipeline\n",
    "\n",
    "rate = 0.001\n",
    "logits = SignNet(sign, image_shape, n_classes)\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=one_hot_y)\n",
    "loss_operation = tf.reduce_mean(cross_entropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = rate)\n",
    "training_operation = optimizer.minimize(loss_operation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_y, 1))\n",
    "accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "def evaluate(X_data, y_data):\n",
    "    num_examples = len(X_data)\n",
    "    total_accuracy = 0\n",
    "    sess = tf.get_default_session()\n",
    "    for offset in range(0, num_examples, BATCH_SIZE):\n",
    "        batch_x, batch_y = X_data[offset:offset+BATCH_SIZE], y_data[offset:offset+BATCH_SIZE]\n",
    "        accuracy = sess.run(accuracy_operation, feed_dict={sign: batch_x, y: batch_y})\n",
    "        total_accuracy += (accuracy * len(batch_x))\n",
    "    return 100 * total_accuracy / num_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Validate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    num_examples = len(X_train)\n",
    "    \n",
    "    print(\"Training...\")\n",
    "    print()\n",
    "    for i in range(EPOCHS):\n",
    "        X_train, y_train = shuffle(X_train, y_train)\n",
    "        for offset in range(0, num_examples, BATCH_SIZE):\n",
    "            end = offset + BATCH_SIZE\n",
    "            batch_x, batch_y = X_train[offset:end], y_train[offset:end]\n",
    "            sess.run(training_operation, feed_dict={sign: batch_x, y: batch_y})\n",
    "\n",
    "        validation_accuracy = evaluate(X_valid, y_valid)\n",
    "        print(\"EPOCH {} ...\".format(i+1))\n",
    "        print(\"Validation Accuracy = {:2.2f}%\".format(validation_accuracy))\n",
    "        print()\n",
    "        \n",
    "    saver.save(sess, './network')\n",
    "    print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
    "\n",
    "    test_accuracy = evaluate(X_test, y_test)\n",
    "    print(\"Test Accuracy = {:2.2f}%\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 3: Test a Model on New Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Output the Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from scipy import misc\n",
    "from numpy import uint8\n",
    "\n",
    "X_samples = []\n",
    "y_samples = []\n",
    "for label, name in classes.values:\n",
    "    file = \"data/extra/{}.png\".format(label)\n",
    "    if os.path.isfile(file):\n",
    "        image = misc.imread(file)\n",
    "        previewImage(image, label, name)\n",
    "        X_samples.append(image)\n",
    "        y_samples.append(uint8(label))\n",
    "\n",
    "X_samples = normalize(X_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the Sign Type for Each Image & Analyze Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
    "    predicted = sess.run(tf.nn.top_k(tf.nn.softmax(logits), k=1),feed_dict={sign: X_samples, y: y_samples})[1]\n",
    "\n",
    "correct_samples = 0\n",
    "for i in range(len(X_samples)):\n",
    "    if (y_samples[i] == predicted[i]):\n",
    "        correct_samples += 1\n",
    "    print(\"sample:\", y_samples[i], \"- predicted:\", predicted[i])\n",
    "\n",
    "sample_accuracy = 100.0 / len(y_samples) * correct_samples\n",
    "print(\"Sample Accuracy = {:2.2f}% ({} out of {})\".format(sample_accuracy, correct_samples, len(y_samples)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Top 5 Softmax Probabilities For Each Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
    "    probabilities = sess.run(tf.nn.top_k(tf.nn.softmax(logits), k=5),feed_dict={sign: X_samples, y: y_samples})\n",
    "\n",
    "for i in range(len(X_samples)):\n",
    "    print(\"{}:\".format(y_samples[i]))\n",
    "    for j in range(len(probabilities[0][i])):\n",
    "        print(\" {}: {:2.2f}%\".format(probabilities[1][i][j], probabilities[0][i][j]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
